{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f8e36d-ecf1-4524-bea4-1cd72a56677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamenev_v/miniconda3/envs/gpuenv/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dcec5c7-7642-4e7a-9e8f-cb1ccb2cfa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/kamenev_v/Deepfake_proj/DeepFakeDetection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2284d10d-6522-41f6-aa45-ea17ce348f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib.data.dataset import *\n",
    "from lib.utils import *\n",
    "from lib.training.train_model import *\n",
    "from lib.models.FTFD import *\n",
    "from lib.models.BaseDetector import *\n",
    "from lib.models.PFD import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e245cb1-543c-41cd-b9bf-debce34b7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c42a98-10d3-41ce-b8ef-3861be09ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 96\n",
    "audio_size_up = 96\n",
    "audio_size_d = 768\n",
    "# transform_image = tt.Compose([tt.ToPILImage(),tt.Resize(image_size),tt.CenterCrop(image_size),\n",
    "#                               tt.ToTensor(),\n",
    "#                                  tt.RandomHorizontalFlip(p=0.3),\n",
    "#                                      tt.RandomRotation(degrees=7),\n",
    "#                                      AddGaussianNoise(p=0.5,mean=0,std=0.1)])\n",
    "transform_image = tt.Compose([tt.Resize(image_size),tt.CenterCrop(image_size)])\n",
    "                                 # tt.RandomHorizontalFlip(p=0.3),\n",
    "                                 #     tt.RandomRotation(degrees=7),\n",
    "                                 #     AddGaussianNoise(p=0.3,mean=0.5,std=0.1)])\n",
    "transform_upsampled_audio = tt.Compose([tt.Resize(audio_size_up),tt.CenterCrop(audio_size_up)])\n",
    "transform_default_audio = tt.Compose([tt.Resize(audio_size_d),tt.CenterCrop(audio_size_d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e36c582-748a-4b27-80ce-a2d6dca680c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6420]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This is fake'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = DeepFakeDetector(num_of_input_imgs=3,\n",
    "                       confidence_face=0.95,patch_mode=False)\n",
    "res = mod.predict_video('../full_dataset/youtube/0001_01_001_adam_sandler.avi')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a9a792-bb01-4d1b-a24e-5e735c60bb04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mres1\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res1' is not defined"
     ]
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164165c-2edf-48f5-b05d-9521fdae06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames,audio,info = read_video('../full_dataset/FakeAVCeleb/RealVideo-FakeAudio/African/women/id00371/00099_fake.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33441d6c-968f-4562-a3ba-0e2a5b9098df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames1,audio1,info1 = read_video('../full_dataset/FakeAVCeleb/RealVideo-FakeAudio/African/men/id00076/00109_fake.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a429f5-260f-4d3c-9fdf-78a034c4b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_waveform(audio1.squeeze(dim=0),44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa988e3-119d-4559-9da3-e739f2737323",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,audio,info = read_video('../full_dataset/FakeAVCeleb/FakeVideo-FakeAudio/African/men/id00076/00109_10_id00476_wavtolip.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0beb90-11ca-4f0b-b422-417fe46fef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b03c334-3cad-4bea-bbe5-ff81de650dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.read_csv('lib/data/FINAL_TRAIN_VA.csv')\n",
    "TEST = pd.read_csv('lib/data/FINAL_TEST_VA.csv')\n",
    "#TRAIN['path'] = TRAIN['path'].apply(lambda x: '/'.join(x.split('/')[3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c278caa3-1f04-4540-b66d-5205aa738526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>video</th>\n",
       "      <th>audio</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fake/id09143_1371__video1_audio0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake/id02587_761__video0_audio1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True/id06355_432__video0_audio0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fake/id00169_2279__video1_audio1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fake/id04774_726__video0_audio1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>Fake/id04374_2166__video1_audio1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>Fake/id05231_2202__video1_audio1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>Fake/id02553_715__video0_audio1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>Fake/id01207_521__video0_audio1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>True/id00579_255__video0_audio0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  path  video  audio  class\n",
       "0     Fake/id09143_1371__video1_audio0    1.0    0.0    1.0\n",
       "1      Fake/id02587_761__video0_audio1    0.0    1.0    1.0\n",
       "2      True/id06355_432__video0_audio0    0.0    0.0    0.0\n",
       "3     Fake/id00169_2279__video1_audio1    1.0    1.0    1.0\n",
       "4      Fake/id04774_726__video0_audio1    0.0    1.0    1.0\n",
       "...                                ...    ...    ...    ...\n",
       "2055  Fake/id04374_2166__video1_audio1    1.0    1.0    1.0\n",
       "2056  Fake/id05231_2202__video1_audio1    1.0    1.0    1.0\n",
       "2057   Fake/id02553_715__video0_audio1    0.0    1.0    1.0\n",
       "2058   Fake/id01207_521__video0_audio1    0.0    1.0    1.0\n",
       "2059   True/id00579_255__video0_audio0    0.0    0.0    0.0\n",
       "\n",
       "[2060 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3794a5b-9d6a-457b-9465-c3ee53cc8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.concat([TRAIN[TRAIN['class']==1].sample(467),TRAIN[TRAIN['class']==0]])\n",
    "TEST = pd.concat([TEST[TEST['class']==1].sample(109),TEST[TEST['class']==0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b358f91-b45f-4081-873a-2557e7e2b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN['path'] = TRAIN['path'].apply(lambda x: 'lib/data/CUSTOMV2/'+x)\n",
    "TEST['path'] = TEST['path'].apply(lambda x: 'lib/data/CUSTOMV2/'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa808e-8d31-4544-b428-faac9f357662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MultimodalModel(3*3,audio_size_default=768,classify=False,return_patch=True) ### IMAGE (T,96,96,3), AUDIO (384,384)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(params = model.parameters())\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "#pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892af9f-5d39-4b1d-947f-440334b3d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN['class'] = TRAIN['class'].apply(lambda x: patch_apply(x))\n",
    "# TEST['class'] = TEST['class'].apply(lambda x: patch_apply(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0bd1e-b4ff-4eec-ad1c-cb2d0fc226a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CelebVADataset(TRAIN,3,transform_image,transform_upsampled_audio,\n",
    "                              transform_default_audio)\n",
    "test_dataset = CelebVADataset(TEST,3,transform_upsampled_audio,transform_upsampled_audio,\n",
    "                             transform_default_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af3dad-18b5-42ad-a6a4-0094bf012b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = train(model=model,opt=optimizer,loss_fn=loss,epochs=50,\n",
    "#           data_tr=train_dataset,data_val=test_dataset,batch=40,patience=7,\n",
    "#           path_to_save='lib/models/FTFD_768_final.pth',patch_v=False,DEVICE=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f62dfa-e670-47db-b6f6-1e9297dcbb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a042876-8f22-4808-85b7-96accc35f032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bcc744-4654-483d-beb5-91988ae5d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.metrics.evaluate import Evaluator\n",
    "checker = Evaluator(type_of_model='av',loss_fn=nn.BCELoss(),patch_v=False)\n",
    "checker.estimate_dataset(test_dataset,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd35e3-0c5c-4282-9bb0-92cdc2ebe34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9d8b5-a07d-48e3-82d7-c6e6b58a0c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256020d-4524-467c-ac22-5eda56343aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
