{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a0d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7efe74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88001cff-d39c-46ed-88db-c027476e6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/kotvkaske/Загрузки/FakeAVCeleb_v1.2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8edf543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.data.dataset import *\n",
    "# from lib.models.PFD import *\n",
    "# from lib.utils import *\n",
    "# from lib.training.train_model import *\n",
    "# from lib.models.FTFD import *\n",
    "# from lib.models.BaseDetector import *\n",
    "# from lib.training.trainerold import train_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2acc18-35b6-4cef-946c-e8742de6ba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FakeVideo-FakeAudio',\n",
       " 'RealVideo-FakeAudio',\n",
       " 'FakeVideo-RealAudio',\n",
       " 'CUSTOM',\n",
       " 'RealVideo-RealAudio',\n",
       " 'meta_data.csv',\n",
       " 'README.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1cbf14-adc6-4571-8582-c0687747b264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>method</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id00076</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>real</td>\n",
       "      <td>A</td>\n",
       "      <td>RealVideo-RealAudio</td>\n",
       "      <td>African</td>\n",
       "      <td>men</td>\n",
       "      <td>00109.mp4</td>\n",
       "      <td>RealVideo-RealAudio/African/men/id00076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id00166</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>real</td>\n",
       "      <td>A</td>\n",
       "      <td>RealVideo-RealAudio</td>\n",
       "      <td>African</td>\n",
       "      <td>men</td>\n",
       "      <td>00010.mp4</td>\n",
       "      <td>RealVideo-RealAudio/African/men/id00166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00173</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>real</td>\n",
       "      <td>A</td>\n",
       "      <td>RealVideo-RealAudio</td>\n",
       "      <td>African</td>\n",
       "      <td>men</td>\n",
       "      <td>00118.mp4</td>\n",
       "      <td>RealVideo-RealAudio/African/men/id00173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id00366</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>real</td>\n",
       "      <td>A</td>\n",
       "      <td>RealVideo-RealAudio</td>\n",
       "      <td>African</td>\n",
       "      <td>men</td>\n",
       "      <td>00118.mp4</td>\n",
       "      <td>RealVideo-RealAudio/African/men/id00366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id00391</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>real</td>\n",
       "      <td>A</td>\n",
       "      <td>RealVideo-RealAudio</td>\n",
       "      <td>African</td>\n",
       "      <td>men</td>\n",
       "      <td>00052.mp4</td>\n",
       "      <td>RealVideo-RealAudio/African/men/id00391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21561</th>\n",
       "      <td>id07689</td>\n",
       "      <td>id06254</td>\n",
       "      <td>-</td>\n",
       "      <td>wav2lip</td>\n",
       "      <td>D</td>\n",
       "      <td>FakeVideo-FakeAudio</td>\n",
       "      <td>Asian (South)</td>\n",
       "      <td>women</td>\n",
       "      <td>00028_id06254_wavtolip.mp4</td>\n",
       "      <td>FakeVideo-FakeAudio/Asian (South)/women/id07689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21562</th>\n",
       "      <td>id07689</td>\n",
       "      <td>id06343</td>\n",
       "      <td>-</td>\n",
       "      <td>wav2lip</td>\n",
       "      <td>D</td>\n",
       "      <td>FakeVideo-FakeAudio</td>\n",
       "      <td>Asian (South)</td>\n",
       "      <td>women</td>\n",
       "      <td>00028_id06343_wavtolip.mp4</td>\n",
       "      <td>FakeVideo-FakeAudio/Asian (South)/women/id07689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21563</th>\n",
       "      <td>id07689</td>\n",
       "      <td>id07008</td>\n",
       "      <td>-</td>\n",
       "      <td>wav2lip</td>\n",
       "      <td>D</td>\n",
       "      <td>FakeVideo-FakeAudio</td>\n",
       "      <td>Asian (South)</td>\n",
       "      <td>women</td>\n",
       "      <td>00028_id07008_wavtolip.mp4</td>\n",
       "      <td>FakeVideo-FakeAudio/Asian (South)/women/id07689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21564</th>\n",
       "      <td>id07689</td>\n",
       "      <td>id07377</td>\n",
       "      <td>-</td>\n",
       "      <td>wav2lip</td>\n",
       "      <td>D</td>\n",
       "      <td>FakeVideo-FakeAudio</td>\n",
       "      <td>Asian (South)</td>\n",
       "      <td>women</td>\n",
       "      <td>00028_id07377_wavtolip.mp4</td>\n",
       "      <td>FakeVideo-FakeAudio/Asian (South)/women/id07689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21565</th>\n",
       "      <td>id07689</td>\n",
       "      <td>id07686</td>\n",
       "      <td>-</td>\n",
       "      <td>wav2lip</td>\n",
       "      <td>D</td>\n",
       "      <td>FakeVideo-FakeAudio</td>\n",
       "      <td>Asian (South)</td>\n",
       "      <td>women</td>\n",
       "      <td>00028_id07686_wavtolip.mp4</td>\n",
       "      <td>FakeVideo-FakeAudio/Asian (South)/women/id07689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21566 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source  target1 target2   method category                 type  \\\n",
       "0      id00076        -       -     real        A  RealVideo-RealAudio   \n",
       "1      id00166        -       -     real        A  RealVideo-RealAudio   \n",
       "2      id00173        -       -     real        A  RealVideo-RealAudio   \n",
       "3      id00366        -       -     real        A  RealVideo-RealAudio   \n",
       "4      id00391        -       -     real        A  RealVideo-RealAudio   \n",
       "...        ...      ...     ...      ...      ...                  ...   \n",
       "21561  id07689  id06254       -  wav2lip        D  FakeVideo-FakeAudio   \n",
       "21562  id07689  id06343       -  wav2lip        D  FakeVideo-FakeAudio   \n",
       "21563  id07689  id07008       -  wav2lip        D  FakeVideo-FakeAudio   \n",
       "21564  id07689  id07377       -  wav2lip        D  FakeVideo-FakeAudio   \n",
       "21565  id07689  id07686       -  wav2lip        D  FakeVideo-FakeAudio   \n",
       "\n",
       "                race gender                        path  \\\n",
       "0            African    men                   00109.mp4   \n",
       "1            African    men                   00010.mp4   \n",
       "2            African    men                   00118.mp4   \n",
       "3            African    men                   00118.mp4   \n",
       "4            African    men                   00052.mp4   \n",
       "...              ...    ...                         ...   \n",
       "21561  Asian (South)  women  00028_id06254_wavtolip.mp4   \n",
       "21562  Asian (South)  women  00028_id06343_wavtolip.mp4   \n",
       "21563  Asian (South)  women  00028_id07008_wavtolip.mp4   \n",
       "21564  Asian (South)  women  00028_id07377_wavtolip.mp4   \n",
       "21565  Asian (South)  women  00028_id07686_wavtolip.mp4   \n",
       "\n",
       "                                             full_path  \n",
       "0              RealVideo-RealAudio/African/men/id00076  \n",
       "1              RealVideo-RealAudio/African/men/id00166  \n",
       "2              RealVideo-RealAudio/African/men/id00173  \n",
       "3              RealVideo-RealAudio/African/men/id00366  \n",
       "4              RealVideo-RealAudio/African/men/id00391  \n",
       "...                                                ...  \n",
       "21561  FakeVideo-FakeAudio/Asian (South)/women/id07689  \n",
       "21562  FakeVideo-FakeAudio/Asian (South)/women/id07689  \n",
       "21563  FakeVideo-FakeAudio/Asian (South)/women/id07689  \n",
       "21564  FakeVideo-FakeAudio/Asian (South)/women/id07689  \n",
       "21565  FakeVideo-FakeAudio/Asian (South)/women/id07689  \n",
       "\n",
       "[21566 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('meta_data.csv')\n",
    "data.rename(columns={'Unnamed: 9':'full_path'},inplace=True)\n",
    "data['full_path'] = data['full_path'].apply(lambda x: '/'.join(x.split('/')[1:]))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da88ab78-c7bd-402a-a62b-82d560203395",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_video' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7643/1167991744.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..FakeVideo-FakeAudio/African/men/id00076/00109_10_id00476_wavtolip.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'read_video' is not defined"
     ]
    }
   ],
   "source": [
    "_,audio,info = read_video('..FakeVideo-FakeAudio/African/men/id00076/00109_10_id00476_wavtolip.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656d167-1ed5-40ab-850d-4eb8bfab28f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### В итоге всего 500 униклаьных объектов (видео+аудио), из них все остальные получаются дф и тд.. Поэтому разбиваем на трейн/тест эти 500 объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c219f28-3ca1-4121-8a7e-a5975eecfe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source                                       id00475\n",
      "target1                                            -\n",
      "target2                                            -\n",
      "method                                          real\n",
      "category                                           A\n",
      "type                             RealVideo-RealAudio\n",
      "race                                         African\n",
      "gender                                           men\n",
      "path                                       00099.mp4\n",
      "full_path    RealVideo-RealAudio/African/men/id00475\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j in range(5):\n",
    "    print(data.iloc[5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acc72efe-fe4f-4408-a6ce-072b4577950e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>method</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13872</th>\n",
       "      <td>id01225</td>\n",
       "      <td>id01231</td>\n",
       "      <td>-</td>\n",
       "      <td>wav2lip</td>\n",
       "      <td>C</td>\n",
       "      <td>FakeVideo-RealAudio</td>\n",
       "      <td>Caucasian (American)</td>\n",
       "      <td>women</td>\n",
       "      <td>00300_id01231_wavtolip.mp4</td>\n",
       "      <td>FakeVideo-RealAudio/Caucasian (American)/women...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>id00709</td>\n",
       "      <td>id01126</td>\n",
       "      <td>-</td>\n",
       "      <td>wav2lip</td>\n",
       "      <td>D</td>\n",
       "      <td>FakeVideo-FakeAudio</td>\n",
       "      <td>Caucasian (European)</td>\n",
       "      <td>men</td>\n",
       "      <td>00206_id01126_wavtolip.mp4</td>\n",
       "      <td>FakeVideo-FakeAudio/Caucasian (European)/men/i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source  target1 target2   method category                 type  \\\n",
       "13872  id01225  id01231       -  wav2lip        C  FakeVideo-RealAudio   \n",
       "19971  id00709  id01126       -  wav2lip        D  FakeVideo-FakeAudio   \n",
       "\n",
       "                       race gender                        path  \\\n",
       "13872  Caucasian (American)  women  00300_id01231_wavtolip.mp4   \n",
       "19971  Caucasian (European)    men  00206_id01126_wavtolip.mp4   \n",
       "\n",
       "                                               full_path  \n",
       "13872  FakeVideo-RealAudio/Caucasian (American)/women...  \n",
       "19971  FakeVideo-FakeAudio/Caucasian (European)/men/i...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267887c-3be4-4657-917c-9242ff59a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.read_csv('lib/data/FINAL_TRAIN_P2.csv')\n",
    "TEST = pd.read_csv('lib/data/FINAL_TEST_P2.csv')\n",
    "# TRAIN['path']=TRAIN['path'].apply(lambda x: 'lib/data/MixedData/'+x)\n",
    "# TEST['path']=TEST['path'].apply(lambda x: 'lib/data/MixedData/'+x)\n",
    "TRAIN['class'] = TRAIN['class'].apply(lambda x: torch.tensor(x,dtype=torch.float32))\n",
    "TEST['class'] = TEST['class'].apply(lambda x: torch.tensor(x,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124782dd-c683-4a1b-8803-4ae1f1ffed69",
   "metadata": {},
   "source": [
    "## Data Loading&Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee612a42-d9a0-41fa-bb8b-5cc6f7b70691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_apply(x):\n",
    "    return torch.tensor([[x,x],[x,x]],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea17ea-0340-47c2-9411-6ab7b1534af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6fa5b-36c4-4eec-a789-2f194713f809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lib/data/MixedData/True/simswappic_107223.jpg</td>\n",
       "      <td>tensor(0.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lib/data/MixedData/True/01687.png</td>\n",
       "      <td>tensor(0.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lib/data/MixedData/Fake/newpic_977.jpgresult.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lib/data/MixedData/Fake/3981.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lib/data/MixedData/Fake/266.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12271</th>\n",
       "      <td>lib/data/CUSTOMV2/Fake/id01637_1935__video1_au...</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12272</th>\n",
       "      <td>lib/data/MixedData/Fake/swappicm_558.jpgresult...</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12273</th>\n",
       "      <td>lib/data/MixedData/Fake/newpicm_735.jpgresult.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12274</th>\n",
       "      <td>lib/data/MixedData/Fake/newpicm_598.jpgresult.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12275</th>\n",
       "      <td>lib/data/MixedData/True/380.jpg</td>\n",
       "      <td>tensor(0.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path       class\n",
       "0          lib/data/MixedData/True/simswappic_107223.jpg  tensor(0.)\n",
       "1                      lib/data/MixedData/True/01687.png  tensor(0.)\n",
       "2       lib/data/MixedData/Fake/newpic_977.jpgresult.jpg  tensor(1.)\n",
       "3                       lib/data/MixedData/Fake/3981.jpg  tensor(1.)\n",
       "4                        lib/data/MixedData/Fake/266.jpg  tensor(1.)\n",
       "...                                                  ...         ...\n",
       "12271  lib/data/CUSTOMV2/Fake/id01637_1935__video1_au...  tensor(1.)\n",
       "12272  lib/data/MixedData/Fake/swappicm_558.jpgresult...  tensor(1.)\n",
       "12273  lib/data/MixedData/Fake/newpicm_735.jpgresult.jpg  tensor(1.)\n",
       "12274  lib/data/MixedData/Fake/newpicm_598.jpgresult.jpg  tensor(1.)\n",
       "12275                    lib/data/MixedData/True/380.jpg  tensor(0.)\n",
       "\n",
       "[12276 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80035c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN['class'] = TRAIN['class'].apply(lambda x: patch_apply(x))\n",
    "TEST['class'] = TEST['class'].apply(lambda x: patch_apply(x))\n",
    "train_dataset = DeepFakeDataset(TRAIN)\n",
    "test_dataset = DeepFakeDataset(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58eacc-f3ed-4bb8-8d18-a9a9c7c77de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lib/data/MixedData/True/simswappic_107223.jpg</td>\n",
       "      <td>tensor(0.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lib/data/MixedData/True/01687.png</td>\n",
       "      <td>tensor(0.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lib/data/MixedData/Fake/newpic_977.jpgresult.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lib/data/MixedData/Fake/3981.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lib/data/MixedData/Fake/266.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12271</th>\n",
       "      <td>lib/data/CUSTOMV2/Fake/id01637_1935__video1_au...</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12272</th>\n",
       "      <td>lib/data/MixedData/Fake/swappicm_558.jpgresult...</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12273</th>\n",
       "      <td>lib/data/MixedData/Fake/newpicm_735.jpgresult.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12274</th>\n",
       "      <td>lib/data/MixedData/Fake/newpicm_598.jpgresult.jpg</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12275</th>\n",
       "      <td>lib/data/MixedData/True/380.jpg</td>\n",
       "      <td>tensor(0.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path       class\n",
       "0          lib/data/MixedData/True/simswappic_107223.jpg  tensor(0.)\n",
       "1                      lib/data/MixedData/True/01687.png  tensor(0.)\n",
       "2       lib/data/MixedData/Fake/newpic_977.jpgresult.jpg  tensor(1.)\n",
       "3                       lib/data/MixedData/Fake/3981.jpg  tensor(1.)\n",
       "4                        lib/data/MixedData/Fake/266.jpg  tensor(1.)\n",
       "...                                                  ...         ...\n",
       "12271  lib/data/CUSTOMV2/Fake/id01637_1935__video1_au...  tensor(1.)\n",
       "12272  lib/data/MixedData/Fake/swappicm_558.jpgresult...  tensor(1.)\n",
       "12273  lib/data/MixedData/Fake/newpicm_735.jpgresult.jpg  tensor(1.)\n",
       "12274  lib/data/MixedData/Fake/newpicm_598.jpgresult.jpg  tensor(1.)\n",
       "12275                    lib/data/MixedData/True/380.jpg  tensor(0.)\n",
       "\n",
       "[12276 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EffNetb1(patch=False,pretrained_folder = 'lib/models/b1_patch.pth')\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.BCELoss()\n",
    "res = train_old(model,optimizer,loss,50,train_dataset,test_dataset,False,'lib/models/b1_default.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf4a7d-90f6-4558-ab5b-61708cb3f077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ba3f1-ccb1-4856-9368-ad4df00e07d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluator\n\u001b[1;32m      2\u001b[0m checker \u001b[38;5;241m=\u001b[39m Evaluator(type_of_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mav\u001b[39m\u001b[38;5;124m'\u001b[39m,loss_fn\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss(),patch_v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mchecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Deepfake_proj/DeepFakeDetection/lib/metrics/evaluate.py:21\u001b[0m, in \u001b[0;36mEvaluator.estimate_dataset\u001b[0;34m(self, dataset, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     20\u001b[0m val_loss,running_corrects,processed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (X_batch_image, X_batch_audio_up,X_batch_audio_d), Y_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     22\u001b[0m     Y_batch \u001b[38;5;241m=\u001b[39m Y_batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     23\u001b[0m     Y_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(Y_batch,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from lib.metrics.evaluate import Evaluator\n",
    "checker = Evaluator(type_of_model='av',loss_fn=nn.BCELoss(),patch_v=True)\n",
    "checker.estimate_dataset(test_dataset,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358ecc2-9b0d-4021-a0a5-abab156b40a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
